# -*- coding: utf-8 -*-
"""Multi_Voz-Texto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NT8DGcmWNdSnPSDLNyyMnSmQ2VfHBvQ3
"""

#DEPENDENCIAS PARA EL PROYECTO
!pip install -q transformers sentencepiece torch gtts pydub SpeechRecognition
!sudo apt update && sudo apt install -y ffmpeg

# Instalar dependencias si aún no lo has hecho
# !pip install transformers sentencepiece torch gtts pydub SpeechRecognition

from transformers import pipeline #generar texto con modelos
#respuesta en voz
from gtts import gTTS
from pydub import AudioSegment
from pydub.playback import play
import speech_recognition as sr #voz a texto
#Mostrar o guardar imágenes
from pathlib import Path
from PIL import Image
import os

# === TEXTO A TEXTO ===

#Para generar resúmenes en inglés
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

def resumir(texto):
    resumen = summarizer(texto, max_length=100, min_length=25, do_sample=False) #extraer el resumen en sí.
    return resumen[0]['summary_text']

# Traduce textos del inglés al españo
translator = pipeline("translation_en_to_es", model="Helsinki-NLP/opus-mt-en-es", truncation=True)

#Toma un texto en inglés como entrada.
def traducir(texto):
    traduccion = translator(texto, max_length=256, truncation=True)
    return traduccion[0]['translation_text']

# GENERAR
generator = pipeline("text-generation", model="gpt2") #GPT-2 entrenado por OpenAI y es capaz de continuar textos de forma coherente.

#recibe un texto como prompt (inicio del texto).
def generar(texto):
    respuesta = generator(texto, max_new_tokens=50)  # No uses max_length
    return respuesta[0]['generated_text']

# === TEXTO A VOZ ===

def texto_a_voz(texto, nombre_archivo="voz.mp3", idioma="es"):
      tts = gTTS("Hola, esto es una prueba", lang="es")
      tts.save("audio.mp3")

      # Verifica que el archivo existe
      print("Archivo generado:", os.path.exists("audio.mp3"))

      # Mostrar reproductor
      display(Audio("audio.mp3", autoplay=False))

# === VOZ A TEXTO ===

def voz_a_texto(ruta_audio="audio.wav"):
    r = sr.Recognizer() #Crea un reconocedor de voz
    with sr.AudioFile(ruta_audio) as source:
        audio = r.record(source) # Carga todo el audio del archivo
    try:
        texto = r.recognize_google(audio, language="es-ES")  # servicio de Google para que lo transcriba
        return texto
    #Errores
    except sr.UnknownValueError:
        return "No se entendió el audio"
    except sr.RequestError as e:
        return f"Error con el servicio: {e}"

#Prueba
if __name__ == "__main__":
    texto_demo = "Transformers are deep learning models introduced in 2017. They have revolutionized NLP."

    print("RESUMEN:")
    print(resumir(texto_demo))

    print("\nTRADUCCIÓN (EN → ES):")
    print(traducir("Hello, how are you? I am testing this translation model."))

    print("\nGENERACIÓN DE TEXTO:")
    print(generar("On Friday I went out with my friends to the park to play,"))

    print("\nTEXTO A VOZ (se reproducirá el audio):")
    texto_a_voz("Hola, esto es una prueba de texto a voz usando Python.")

    print("\nVOZ A TEXTO (desde archivo):")
    #Tener un archivo 'audio.wav' grabado previamente en la misma carpeta
    if Path("audio.wav").exists():
        print(voz_a_texto("audio.wav"))
    else:
        print(" No se encontró el archivo 'audio.wav'. Graba uno primero.")