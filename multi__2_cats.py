# -*- coding: utf-8 -*-
"""Multi_ 2_cats.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Huwpngn4mtPxgtxD4jzt01J2fiLJGGp
"""

from google.colab import files
files.upload()  # Sube kaggle.json desde tu cuenta de Kaggle

import os
import torch # núcleo de PyTorch: tensores, operaciones, entrenamiento en GPU
import torch.nn as nn # Módulo para construir redes neuronales
import torchvision.transforms as transforms # transformaciones para imágenes
import torchvision.datasets as dset #datasets comunes como MNIST, CIFAR-10, o permite cargar carpetas personalizadas.
import torchvision.utils as vutils # convertir lotes de imágenes en grids y guardarlas
from torch.utils.data import DataLoader #agrupar tus datos en batches, mezcla
import matplotlib.pyplot as plt # mostrar imágenes

#contiene imágenes de gatos y perros de diferentes razas
!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz
!mkdir -p data/pets#Crea la carpeta
!tar -xzf images.tar.gz -C data/pets #Descomprime

from torchvision.datasets import ImageFolder #carga datasets organizados en carpetas
from torchvision.io import read_image #utilidades para leer imágenes
from torchvision.datasets.folder import default_loader
from torch.utils.data import DataLoader, Dataset#crear propio dataset personalizado
from PIL import Image # abrir imágenes.
import os

#Clase Hereda de torch.utils.data.Dataset personalizar como se leen las imagenes
class OxfordPetDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        #guarda una lista con la ruta completa de todas las imágenes
        self.image_paths = [
            os.path.join(root_dir, fname)
            for fname in os.listdir(root_dir)
            if fname.endswith(".jpg")
        ]
        self.transform = transform #redimencionar

    # Devuelve la cantidad total de imágenes disponibles en el dataset.
    def __len__(self):
        return len(self.image_paths)

    #Obtener una imagen
    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, 0  # el segundo valor es solo un placeholder

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

#Define Tamaño final y cantidad
image_size = 128
batch_size = 128

#Transformaciones
transform = transforms.Compose([
    transforms.Resize(image_size),#redimenciona
    transforms.CenterCrop(image_size),#Recorta
    transforms.ToTensor(),#convierte a tensor con valores [0,1]
    transforms.Normalize((0.5,), (0.5,)) #Normaliza canal, asume escala de grises
])

#Dataset personalizado
dataset = OxfordPetDataset(root_dir="data/pets/images", transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) #Crea batches de 128 imágenes y mezcla aleatoriamente las carpetas

import torch

# Configuración del dispositivo
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"✅ Usando dispositivo: {device}")

# Parámetros de arquitectura DCGAN
nz = 100     # Tamaño del vector de ruido
ngf = 64     # Filtros generador
ndf = 64     # Filtros discriminador
nc = 3       # Canales (3 para RGB)

# ==== Hiperparámetros de entrenamiento ====
lr = 0.0002
beta1 = 0.5
num_epochs = 2
batch_size = 128
image_size = 128

#Toma como entrada un vector de ruido (latent vector) y lo transforma progresivamentehasta generar
#una imagen RGB de tamaño 128x128x3
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            #Primera Capa
            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),  # 4x4
            nn.BatchNorm2d(ngf*8), nn.ReLU(True),
            #Segunda Capa
            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),  # 8x8
            nn.BatchNorm2d(ngf*4), nn.ReLU(True),
            #Tercera Capa
            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),  # 16x16
            nn.BatchNorm2d(ngf*2), nn.ReLU(True),
            #Cuarta Capa
            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),  # 32x32
            nn.BatchNorm2d(ngf), nn.ReLU(True),
            #Quinta Capa
            nn.ConvTranspose2d(ngf, ngf//2, 4, 2, 1, bias=False),  # 64x64
            nn.BatchNorm2d(ngf//2), nn.ReLU(True),
            #Sexta Capa
            nn.ConvTranspose2d(ngf//2, nc, 4, 2, 1, bias=False),  # 128x128
            nn.Tanh() #normaliza los valores de salida a [-1, 1]
        )
    #Pasa el vector de entrada por toda la red secuencial.
    def forward(self, input):
        return self.main(input)

#Discriminador, clasificar si una imagen es real o generada por el generador,
#usando una red convolucional que reduce progresivamente la resolución hasta producir un único valor entre 0 y 1
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            #Capa 1: Conv inicial
            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),        # 128 → 64
            nn.LeakyReLU(0.2, inplace=True),
            #Capa 2: 64 → 32
            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),     # 64 → 32
            nn.BatchNorm2d(ndf*2),
            nn.LeakyReLU(0.2, inplace=True),
            #Capa 3: 32 → 16
            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),   # 32 → 16
            nn.BatchNorm2d(ndf*4),
            nn.LeakyReLU(0.2, inplace=True),
            #Capa 4: 16 → 8
            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),   # 16 → 8
            nn.BatchNorm2d(ndf*8),
            nn.LeakyReLU(0.2, inplace=True),
            # Capa 5: 8 → 4
            nn.Conv2d(ndf*8, ndf*16, 4, 2, 1, bias=False),  # 8 → 4
            nn.BatchNorm2d(ndf*16),
            nn.LeakyReLU(0.2, inplace=True),
            #Capa final: 4 → 1
            nn.Conv2d(ndf*16, 1, 4, 1, 0, bias=False),      # 4 → 1
            nn.Sigmoid()
        )

    #Pasa la imagen (real o generada) por todas las capas del discriminador.
    def forward(self, input):
        return self.main(input)

#Entrenamiento de GAN
#Inicialización de los modelos
netG = Generator().to(device)
netD = Discriminator().to(device)
#Inicialización de Pesos
netG.apply(lambda m: nn.init.normal_(m.weight.data, 0.0, 0.02) if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)) else None)
netD.apply(lambda m: nn.init.normal_(m.weight.data, 0.0, 0.02) if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)) else None)

criterion = nn.BCELoss() #Función de pérdida
fixed_noise = torch.randn(64, nz, 1, 1, device=device)#Ruido fijo para evaluación visual
#Optimizadores
optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))

real_label = 1.
fake_label = 0.
os.makedirs("output", exist_ok=True)

#Bucle de entrenamiento
for epoch in range(num_epochs):
    for i, (data, _) in enumerate(dataloader):
      #Entrenamiento del Discriminador (netD)
        netD.zero_grad()
        real = data.to(device)# Batch de imágenes reales
        b_size = real.size(0)
        label = torch.full((b_size,), real_label, device=device)# Etiquetas 1
        output = netD(real).view(-1) # Predicción de real/fake
        errD_real = criterion(output, label)# Desconecta del gradiente de G
        errD_real.backward()
        D_x = output.mean().item()

        #Evalúa al discriminador con imágenes falsas.
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        fake = netG(noise) # Genera imágenes falsas
        label.fill_(fake_label)# Etiquetas 0
        output = netD(fake.detach()).view(-1)
        errD_fake = criterion(output, label)
        errD_fake.backward()
        D_G_z1 = output.mean().item()
        #Se suma la pérdida y se actualiza netD.
        errD = errD_real + errD_fake
        optimizerD.step()

      #Entrenamiento del Generador (netG)
        netG.zero_grad()
        label.fill_(real_label) # Quiere engañar al discriminador
        output = netD(fake).view(-1)
        #errG pérdida del generador.
        errG = criterion(output, label)
        errG.backward()
        D_G_z2 = output.mean().item()
        optimizerG.step()

        if i % 100 == 0:
            print(f"[{epoch}/{num_epochs}] [{i}/{len(dataloader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}")

    #Guardar imágenes generadas
    with torch.no_grad():
        fake = netG(fixed_noise).detach().cpu()
    vutils.save_image(fake, f"output/fake_epoch_{epoch:03d}.png", normalize=True)