# -*- coding: utf-8 -*-
"""Multi_1_pt1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Igdt7DmMUtU485ABJpXNviBIWPXkzgJP

# Importación de librerias

Librerias Generales
"""

import cv2 #OpenV > Procesamiento de imágenes y video.
import numpy as np #arrays (vectores, matrices, etc.).
import pandas as pd #Análisis y manipulación de datos tabulares (como archivos CSV).
from pathlib import Path #Rutas de archivos y directorios
import os
import tensorflow as tf #construir y entrenar redes neuronale
from tensorflow import keras #API de TensorFlow para crear redes neuronales sencillas.
import matplotlib.pyplot as pl#Para crear gráficos y visualizar datos. pyplot permite dibujar
import sklearn #machine learning clásico.

#imag HD

from PIL import Image #abrir, editar y guardar imágenes en distintos formatos
import io #flujos de datos en memoria, como si fueran archivos.
import zipfile

"""# Analisis Imagen Blanco y Negro"""

# Cargar dataset MNIST desde Keras
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalizar a valores entre 0 y 1
x_train = x_train / 255.0
x_test = x_test / 255.0

# Añadir dimensión de canal (blanco y negro = 1 canal)
x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]
#Necesario porque muchas redes convolucionales esperan entradas con 4 dimensiones

print("Forma de entrada:", x_train.shape)

#Modelo secuencias, para añadir las capas una tras otra en orde
model = keras.models.Sequential([
    # Entrada en B/N

    #32 filtros, de tamaño 3x3, introduce no linealidad, y forma las imagenes (alto, ancho, canal gris)
    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), #primera Capa
    keras.layers.MaxPooling2D((2, 2)),#Reducción de dimensionalidad

    #64 filtros, de tamaño 3x3, introduce no linealidad
    keras.layers.Conv2D(64, (3, 3), activation='relu'),#Segunda capa
    keras.layers.MaxPooling2D((2, 2)),

    keras.layers.Flatten(),#Pasa las capas de 2D a 1D para conectarse a la capa densa
    keras.layers.Dense(64, activation='relu'),#Capa densa
    keras.layers.Dense(10, activation='softmax')  # Capa salida con 10 clases en MNIST (0 a 9), valores en probabilidades
])

model.summary()#resumen de lo creado

#Compilación
model.compile(optimizer='adam',#algoritmo eficiente para actualizar los pesos
              loss='sparse_categorical_crossentropy', #adecuada para clasificación con etiquetas enteras
              metrics=['accuracy'])#para medir qué tan bien clasifica.

# Entrena el modelo por 5 épocas
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))#entrena Valida y guarda

#Evalúa el modelo teniendo en cuenta la perdida, la precision (con porcentajes de aciertos) e imprime
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print("\nPrecisión en el conjunto de prueba:", test_acc)


import numpy as np #arrays

#Usa el modelo antterior para predicir las probabilidades de cada clase para cada imagen
predictions = model.predict(x_test)

# Mostrar la imagen de prueba y su predicción
plt.imshow(x_test[9].reshape(28, 28), cmap='gray') # Muestra la imagen de la poscicion "9", la convierte a 2D y asugura escala de grises
plt.title(f"Predicción: {np.argmax(predictions[9])}") # predice la imagen, devuelve el índice de la clase con mayor probabilidad
plt.axis('off')
plt.show()

"""# Analisis 16 Bits"""

img_8bit = cv2.imread("/content/dataset/imagen1.jpeg")#Lee la imagen 8 bits por canal
img_16bit = (img_8bit.astype(np.uint16) * 256)  # covierte a 16 y Escala de 0–255 a 0–65535
cv2.imwrite("/content/dataset/imagen1.jpeg", img_16bit) #Guarda sobrescribiendo el archivo original.

# Verifica que tiene 16 bits
print("Tipo de imagen:", img_16bit.dtype)  # Debe ser uint16

# 2. Normaliza la imagen al rango [0, 1]
img_float = img_16bit.astype(np.float32) / 65535.0

# 3. Redimensiona a 224x224 (lo que espera ResNet50/Xception)
img_resized = cv2.resize(img_float, (224, 224))

# 4. Verifica de que tenga 3 canales (RGB)
if len(img_resized.shape) == 2:
    img_resized = np.stack([img_resized]*3, axis=-1)  # Escala de grises a RGB
elif img_resized.shape[2] == 1:
    img_resized = np.concatenate([img_resized]*3, axis=-1)

# 5. Preprocesamiento para ResNet50 (espera datos en 0–255)
#ResNet50 (reordenamiento de canales, normalización).
img_ready = keras.applications.resnet50.preprocess_input(img_resized * 255)
img_batch = np.expand_dims(img_ready, axis=0)  # Shape (1, 224, 224, 3) dimensión extra al inicio para simular un lote de 1 imagen.

# 6. Cargar modelo preentrenado en el dataset ImageNet
model = keras.applications.ResNet50(weights="imagenet")

# 7. Predecir
preds = model.predict(img_batch)

# 8. Decodificar predicciones
#Convierte las predicciones en nombres de clases legibles + porcentajes.
top_3 = keras.applications.resnet50.decode_predictions(preds, top=3)[0]
#imprime las 3 clases más probables, con su nombre y probabilidad.
print("Predicciones:")
for class_id, name, score in top_3:
    print(f"  {name:>15s}: {score*100:.2f}%")

# 9. Mostrar la imagen original
plt.imshow(img_resized)
plt.title("Imagen 16 bits redimensionada")
plt.axis("off")
plt.show()

"""# Analisis imagen calidad HD"""

#dataset DIV2K_train_HR contiene imágenes de alta resolución
!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip -O DIV2K_train_HR.zip
!unzip -q DIV2K_train_HR.zip -d imagenesHD_dataset #Descomprimir el zip

from google.colab import files
import zipfile

# Parámetros para redimencionar las imagenes
batch_size = 8
img_height = 256
img_width = 256

#Cargar imágenes como dataset para entrenar agrupando en lotes y redimencionandolas
train_ds = tf.keras.utils.image_dataset_from_directory(
    "imagenesHD_dataset",
    seed=123,#Garantizar mismo orden aleatorio
    image_size=(img_height, img_width),
    batch_size=batch_size
)
#imagenesHD_dataset hay  subcarpetas, y cada una representa una clase.

#Guarda los nombres de las subcarpetas
class_names = train_ds.class_names  #importante

print("Clases detectadas:", train_ds.class_names)# Imprime las clases que TensorFlow detectó.

#Organiza las imágenes manualmente en subcarpetas
!mkdir -p imagenesHD_dataset/clase_A
!mkdir -p imagenesHD_dataset/clase_B
!mkdir -p imagenesHD_dataset/clase_C
#clases diferentes por TensorFlow.
!mv imagenesHD_dataset/DIV2K_train_HR/0001.png imagenesHD_dataset/clase_A/#Mueve la imagen

# Definir modelo
model = keras.models.Sequential([#Crea modelo
    keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),#convierte pixeles y define entrada > 3 canal RGB
    keras.layers.Conv2D(32, (3, 3), activation='relu'),#filtros y no linealidad
    keras.layers.MaxPooling2D(),#Redice tamaño mantiene lo más importante
    keras.layers.Conv2D(64, (3, 3), activation='relu'),#nuevo filro para patrones complejos
    keras.layers.MaxPooling2D(),
    keras.layers.Flatten(),#convierte a un vector plano
    keras.layers.Dense(128, activation='relu'),#Capa densa inttermedia para aprender
    keras.layers.Dense(5, activation='softmax')  # Capa densa final con 5 clases
])

#Compila modelo
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#Entrenamiento del modelo
history = model.fit(train_ds, epochs=10)#10 épocas usando la carpeta image_dataset_from_directory

# Mostrar una predicción sobre una imagen del dataset
import matplotlib.pyplot as plt
import numpy as np

for images, labels in train_ds.take(1):#Toma primer lote
    preds = model.predict(images)#Predicción
    # mostrar 5 ejemplos
    for i in range(5):
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(f"Etiqueta real: {class_names[labels[i]]}\nPredicción: {class_names[np.argmax(preds[i])]}")
        plt.axis('off')
        plt.show()